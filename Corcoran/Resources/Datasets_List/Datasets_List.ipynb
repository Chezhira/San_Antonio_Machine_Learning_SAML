{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyforest\n",
    "from pyforest import *\n",
    "\n",
    "import os\n",
    "pyforest.active_imports()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prints the FOLDER STRUCTURE from the Root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = r'C:\\Users\\Boborodono\\Desktop\\San_Antonio\\Resources'\n",
    "print(\"List of all folders and filepaths in '% s':\" % path1) \n",
    "def list_files(dir):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            filepath = root + os.sep + name\n",
    "            r.append(os.path.join(root, name))\n",
    "        print(root)\n",
    "    return r\n",
    "\n",
    "print(list_files(path1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prints the \"csv\" file names in a specific folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to be scanned\n",
    "path2 = \"C:\\\\Users\\\\Boborodono\\\\Desktop\\\\San_Antonio\\\\Resources\\\\BMI_Datasets\"\n",
    "\n",
    "# Using os.scandir() method, scan the specified directory\n",
    "# and yield os.DirEntry object for each file and sub directory\n",
    "\n",
    "print(\"List of all the files in the path '% s':\" % path2)\n",
    "with os.scandir(path2) as itr:\n",
    "    for entry in itr:\n",
    "        # Check if the entry in a file\n",
    "        if entry.name.endswith(\".csv\") and entry.is_file():\n",
    "            # Print entry filename\n",
    "            print(entry.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIST COMPREHENSION: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prints all \".gzip\" files in the Root and subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path3 = \"C:\\\\Users\\\\Boborodono\\\\Desktop\\\\San_Antonio\\\\Resources\"\n",
    "\n",
    "print(\"List of all the files in the path '% s':\" % path3)\n",
    "def list_comp_filepath(dir):\n",
    "    dataset_list = []\n",
    "    # Using list comprehension\n",
    "    return[name for root, dirs, files in os.walk(dir) for name in files if name.endswith(\".gzip\")]\n",
    "\n",
    "\n",
    "comp_filepaths = list_comp_filepath(path3)  \n",
    "print(comp_filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prints all the \"filepaths\" for \"parquet\" files in Root and subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"List of all the filepaths in Root Directory '% s':\" % path3)\n",
    "def list_comp_files(dir):\n",
    "    dataset_list = []\n",
    "    # Using list comprehension\n",
    "    return[os.path.join(root, name) for root, dirs, files in os.walk(dir) for name in files if name.endswith(\".gzip\")]\n",
    "\n",
    "\n",
    "comp_names = list_comp_files(path3)  \n",
    "print(comp_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR LOOPS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prints all the \"file names\" for \"csv\" files in Root and subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path4 = r'C:\\Users\\Boborodono\\Desktop\\San_Antonio\\Resources'\n",
    "print(\"List of all \\\"filenames\\\" in '% s':\" % path4) \n",
    "def list_filenames(dir):\n",
    "    filenames = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            filename = name\n",
    "            if filename.endswith(\".csv\"):\n",
    "                filenames.append(name)\n",
    "    return filenames\n",
    "\n",
    "\n",
    "print(list_filenames(path4))\n",
    "csv_file_names = list_filenames(path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path5 = r'C:\\Users\\Boborodono\\Desktop\\San_Antonio\\Resources'\n",
    "print(\"List of all \\\"filepaths\\\" in '% s':\" % path5) \n",
    "def list_filepaths(path5):\n",
    "    filepaths = []\n",
    "    for root, dirs, files in os.walk(path5):\n",
    "        for name in files:\n",
    "            filepath = root + os.sep + name\n",
    "            if filepath.endswith(\".csv\"):\n",
    "                filepaths.append(os.path.join(root, name))\n",
    "    return filepaths\n",
    "\n",
    "\n",
    "print(list_filepaths(path5))\n",
    "csv_file_paths = list_filepaths(path5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR LOOPS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prints all the \"file names\" for \"gzip\" files in Root and subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path4 = r'C:\\Users\\Boborodono\\Desktop\\San_Antonio\\Resources'\n",
    "print(\"List of all \\\"filenames\\\" in '% s':\" % path4) \n",
    "def list_filenames(dir):\n",
    "    filenames = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            filename = name\n",
    "            if filename.endswith(\".gzip\"):\n",
    "                filenames.append(name)\n",
    "    return filenames\n",
    "\n",
    "\n",
    "print(list_filenames(path4))\n",
    "parquet_file_names = list_filenames(path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"List of all \\\"filepaths\\\" in '% s':\" % path4) \n",
    "def list_filepaths(path4):\n",
    "    filepaths = []\n",
    "    for root, dirs, files in os.walk(path4):\n",
    "        for name in files:\n",
    "            filepath = root + os.sep + name\n",
    "            if filepath.endswith(\".gzip\"):\n",
    "                filepaths.append(os.path.join(root, name))\n",
    "    return filepaths\n",
    "\n",
    "\n",
    "print(list_filepaths(path4))\n",
    "parquet_file_paths = list_filepaths(path4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV - Create a Table cataloguing files in Root + sub-ds and developing shortcuts for easy import and reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Greek Letters to easily import datasets\n",
    "greek_letters = ['alpha ','beta ','gamma ','delta ','epsilon','zeta','eta','theta','iota','kappa','lambda','mu','nu','xi','omicron','pi','rho','sigma','tau','upsilon','phi','chi','psi ','omega']\n",
    "\n",
    "# Number of datasets\n",
    "csv_datasets_count = len(csv_file_names)\n",
    "print(f\"The number of '.csv' files in the Root folder is: \" + str(csv_datasets_count))\n",
    "\n",
    "# Create Dictionary \n",
    "df_start = {\"Greek_Letter_Variable\": (greek_letters[0:csv_datasets_count]),\n",
    "            \"File_Name\": (csv_file_names[0:]), \n",
    "            \"File_Paths\": (csv_file_paths[0:])}\n",
    "\n",
    "# Create DataFrame\n",
    "csv_datasets_df = pd.DataFrame(data=df_start)\n",
    "csv_datasets_df\n",
    "\n",
    "# Add a column concatenating the greek letters and file paths\n",
    "csv_datasets_df[\"Copy_This\"] = csv_datasets_df[\"Greek_Letter_Variable\"] + \" = \" + '\\\"' + csv_datasets_df[\"File_Paths\"] + '\\\"'\n",
    "csv_datasets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "csv_datasets_df = csv_datasets_df[['Greek_Letter_Variable', 'File_Name', 'Copy_This', 'File_Paths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort Table by \"File_Paths\"\n",
    "csv_datasets_df.sort_values(by = ['File_Paths'], ascending=True, inplace = True)\n",
    "csv_datasets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new more compact DataFrame\n",
    "csv_reference_df = csv_datasets_df[['File_Name', 'Copy_This']]\n",
    "csv_reference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference Dataframe\n",
    "csv_quick_data_import_df = csv_datasets_df[['File_Paths']]\n",
    "csv_quick_data_import_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export CSV File\n",
    "csv_datasets_df.to_csv(r'..\\..\\Resources\\Datasets_List\\CSV\\datasets_full_csv.csv', index=False)\n",
    "csv_reference_df.to_csv(r'..\\..\\Resources\\Datasets_List\\CSV\\reference_datasets_csv.csv', index=False)\n",
    "csv_quick_data_import_df.to_csv(r'..\\..\\Resources\\Datasets_List\\CSV\\quick_datasets_csv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet - Create a Table cataloguing files in Root + sub-ds and developing shortcuts for easy import and reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Greek Letters to easily import datasets\n",
    "greek_letters = ['alpha ','beta ','gamma ','delta ','epsilon','zeta','eta','theta','iota','kappa','lambda','mu','nu','xi','omicron','pi','rho','sigma','tau','upsilon','phi','chi','psi ','omega']\n",
    "\n",
    "# Number of datasets\n",
    "parquet_datasets_count = len(parquet_file_names)\n",
    "print(f\"The number of '.gzip' files in the Root folder is: \" + str(parquet_datasets_count))\n",
    "\n",
    "# Create Dictionary \n",
    "df_start = {\"Greek_Letter_Variable\": (greek_letters[0:parquet_datasets_count]),\n",
    "            \"File_Name\": (parquet_file_names[0:]), \n",
    "            \"File_Paths\": (parquet_file_paths[0:])}\n",
    "\n",
    "# Create DataFrame\n",
    "parquet_datasets_df = pd.DataFrame(data=df_start)\n",
    "parquet_datasets_df\n",
    "\n",
    "# Add a column concatenating the greek letters and file paths\n",
    "parquet_datasets_df[\"Copy_This\"] = parquet_datasets_df[\"Greek_Letter_Variable\"] + \" = \" + '\\\"' + parquet_datasets_df[\"File_Paths\"] + '\\\"'\n",
    "parquet_datasets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "parquet_datasets_df = parquet_datasets_df[['Greek_Letter_Variable', 'File_Name', 'Copy_This', 'File_Paths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort Table by \"File_Paths\"\n",
    "parquet_datasets_df.sort_values(by = ['File_Paths'], ascending=True, inplace = True)\n",
    "parquet_datasets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new more compact DataFrame\n",
    "parquet_reference_df = parquet_datasets_df[['File_Name', 'Copy_This']]\n",
    "parquet_reference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference Dataframe\n",
    "parquet_quick_data_import_df = parquet_datasets_df[['File_Paths']]\n",
    "parquet_quick_data_import_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Parquet File\n",
    "parquet_datasets_df.to_csv(r'..\\..\\Resources\\Datasets_List\\Parquet\\datasets_full_parquet.csv', index=False)\n",
    "parquet_reference_df.to_csv(r'..\\..\\Resources\\Datasets_List\\Parquet\\reference_datasets_parquet.csv', index=False)\n",
    "parquet_quick_data_import_df.to_csv(r'..\\..\\Resources\\Datasets_List\\Parquet\\quick_datasets_parquet.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91467934cf79c70e8d3ae65fe6c50c19d67398a8041a0c6998eefdea162cbc23"
  },
  "kernelspec": {
   "display_name": "Lux",
   "language": "python",
   "name": "lux"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
